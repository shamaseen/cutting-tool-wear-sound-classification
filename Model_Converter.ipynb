{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load traning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=8\n",
    "input_shape=(64, 313)\n",
    "weight_path='weights/best_val_model.ckpt'\n",
    "labels={0:\"BASE520\",1:\"BASE635\",2:\"BROKEN520\",3:\"BROKEN635\",4:\"FRESH520\",5:\"FRESH635\",6:\"MODERATE520\",7:\"MODERATE635\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "custom_model= timm.create_model('tf_efficientnet_b1_ns', pretrained=False)\n",
    "# unfreeze layers\n",
    "for params in custom_model.parameters():\n",
    "    params.requires_grad=True\n",
    "\n",
    "# Define the DNN layers with specified names\n",
    "# In traning i have use dnn funtion with custom MLP layers \n",
    "# Here i have just rename the layers to avoid use dnn fucntion\n",
    "custom_model.classifier = nn.Sequential()\n",
    "custom_model.classifier.add_module('dense1', nn.LazyLinear(256))\n",
    "custom_model.classifier.add_module('dropout1', nn.Dropout(0.2))\n",
    "custom_model.classifier.add_module('bn1', nn.LazyBatchNorm1d())\n",
    "custom_model.classifier.add_module('mish1', nn.ReLU())\n",
    "custom_model.classifier.add_module('dense2', nn.LazyLinear(128))\n",
    "custom_model.classifier.add_module('dropout2', nn.Dropout(0.3))\n",
    "custom_model.classifier.add_module('bn2', nn.LazyBatchNorm1d())\n",
    "custom_model.classifier.add_module('mish2', nn.ReLU())\n",
    "custom_model.classifier.add_module('dense3', nn.LazyLinear(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(weight_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change layers name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "state_dict = checkpoint['state_dict']\n",
    "state_dict_v2 = copy.deepcopy(state_dict)\n",
    "for key in state_dict:\n",
    "        post='.'.join(key.split('.')[2:])\n",
    "        state_dict_v2[post] = state_dict_v2.pop(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.load_state_dict(state_dict_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(custom_model, 'weights/full_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model To Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model=torch.load('weights/full_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to inference mode.\n",
    "dummy_input = torch.rand(1, 3, *input_shape)  # (1, 3, 32, 128) by default\n",
    "\n",
    "torch.onnx.export(custom_model, \n",
    "                dummy_input, \n",
    "                \"weights/model.onnx\", \n",
    "                input_names = [\"input\"], # Construct the input name.\n",
    "                output_names =['output'], # Construct the output name.\n",
    "                opset_version=16, # Currently, the ATC tool supports only opset_version=11.\n",
    "                export_params=True,\n",
    "                dynamic_axes={\n",
    "                    \"input\":{0:\"batch_size\"},\n",
    "                    'output':{0:\"batch_size\"}, \n",
    "                }\n",
    "               ) # Dynamic axes of the output is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model To TRT\n",
    "## TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !trtexec --onnx=model.onnx --saveEngine=model_dynamic.trt --minShapes=input:1x3x64x313 --optShapes=input:16x3x64x313 --maxShapes=input:64x3x64x313 --explicitBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
